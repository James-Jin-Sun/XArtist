{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Prepare",
   "id": "af961599becb3538"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-09T02:00:08.505673Z",
     "start_time": "2024-07-09T02:00:07.173412Z"
    }
   },
   "source": [
    "import torch\n",
    "from src.configs import *\n",
    "from src.gan_models import *\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T02:00:09.808817Z",
     "start_time": "2024-07-09T02:00:09.787438Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = 'cpu'\n",
    "# Check if MPS is supported and available\n",
    "if torch.backends.mps.is_available():\n",
    "    print(\"MPS is available on this device.\")\n",
    "    device = torch.device(\"mps\")  # Use MPS device\n",
    "elif torch.cuda.is_available():\n",
    "    print(\"CUDA is available on this device.\")\n",
    "    device = torch.device(\"cuda\")  # Use MPS device\n",
    "else:\n",
    "    print(\"MPS not available, using CPU instead.\")\n",
    "    device = torch.device(\"cpu\")  # Fallback to CPU\n",
    "\n",
    "# device = torch.device('cpu')"
   ],
   "id": "94da532872a23d2c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available on this device.\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T02:00:12.819273Z",
     "start_time": "2024-07-09T02:00:11.958593Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "import time\n",
    "from PIL import Image\n",
    "import src.gan_trainer as gan_trainer"
   ],
   "id": "ae6a456c023cfbe3",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Start Training",
   "id": "7b0698ee47d6fd24"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-09T02:01:06.195004Z",
     "start_time": "2024-07-09T02:00:13.691999Z"
    }
   },
   "cell_type": "code",
   "source": [
    "Image.MAX_IMAGE_PIXELS = None  # Completely removes the limit\n",
    "# or set to a higher limit, for example:\n",
    "Image.MAX_IMAGE_PIXELS = 100_000_000  # set to a more suitable limit\n",
    "start_ts = time.time()\n",
    "print(f'Training started ....')\n",
    "gan_trainer.run()\n",
    "print(f'Training finished ... ({(time.time() - start_ts)/1000} s)')"
   ],
   "id": "90cdda6021c23315",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started ....\n",
      "MPS is available on this device.\n",
      "Category labels': \n",
      "0     abstract_painting\n",
      "1             cityscape\n",
      "2        genre_painting\n",
      "3          illustration\n",
      "4             landscape\n",
      "5         nude_painting\n",
      "6              portrait\n",
      "7    religious_painting\n",
      "8      sketch_and_study\n",
      "9            still_life\n",
      "Name: 1, dtype: object\n",
      "Load images from : ./wikiart/genre_train.csv\n",
      "WikiArt Label filters: ['still_life']\n",
      "Dataset size: 1952\n",
      "G-Model: \n",
      "DCGANGeneratorNet64(\n",
      "  (cons_layers): Sequential(\n",
      "    (0): Unflatten(dim=1, unflattened_size=(128, 1, 1))\n",
      "    (1): ConvTranspose2d(128, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
      "    (2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (11): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (14): Tanh()\n",
      "  )\n",
      ")\n",
      "D-Model: \n",
      "SNDCGANDiscriminatorNet64(\n",
      "  (cons_layers): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (3): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (4): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (5): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (6): Conv2d(256, 512, kernel_size=(8, 8), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
      "    (8): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (9): Flatten(start_dim=1, end_dim=-1)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mgangchu-cg\u001B[0m (\u001B[33mliight\u001B[0m). Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "wandb version 0.17.4 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/Users/typeorigin/PythonProjects/XArtist/training/wandb/run-20240708_220015-eiwrf6z1</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/liight/XArtist/runs/eiwrf6z1' target=\"_blank\">SNDCGAN64-genre-202407082200</a></strong> to <a href='https://wandb.ai/liight/XArtist' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/liight/XArtist' target=\"_blank\">https://wandb.ai/liight/XArtist</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/liight/XArtist/runs/eiwrf6z1' target=\"_blank\">https://wandb.ai/liight/XArtist/runs/eiwrf6z1</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n",
      "Epoch[0], Batch[0] Loss G: -0.6115, Loss D: 1.9972, D(x): 0.0098, D(G(z1)): 0.0069, D(G(z2)): 0.6115\n",
      "Epoch[0], Batch[1] Loss G: -0.1252, Loss D: 2.3008, D(x): 1.6773, D(G(z1)): 1.2956, D(G(z2)): 0.1252\n",
      "Epoch[0], Batch[2] Loss G: 0.0316, Loss D: 1.8176, D(x): 0.4666, D(G(z1)): 0.2841, D(G(z2)): -0.0316\n",
      "Epoch[0], Batch[3] Loss G: 0.0549, Loss D: 1.6217, D(x): 0.4870, D(G(z1)): 0.1087, D(G(z2)): -0.0549\n",
      "Epoch[0], Batch[4] Loss G: 0.2950, Loss D: 1.3542, D(x): 1.0524, D(G(z1)): 0.2796, D(G(z2)): -0.2950\n",
      "Epoch[0], Batch[5] Loss G: 0.6723, Loss D: 1.2011, D(x): 1.3301, D(G(z1)): 0.1697, D(G(z2)): -0.6723\n",
      "Epoch[0], Batch[6] Loss G: 0.4800, Loss D: 1.2795, D(x): 0.7239, D(G(z1)): -0.0675, D(G(z2)): -0.4800\n",
      "Epoch[0], Batch[7] Loss G: 0.5670, Loss D: 1.4417, D(x): 1.3818, D(G(z1)): 0.3866, D(G(z2)): -0.5670\n",
      "Epoch[0], Batch[8] Loss G: 0.6541, Loss D: 1.3740, D(x): 1.0395, D(G(z1)): 0.2129, D(G(z2)): -0.6541\n",
      "Epoch[0], Batch[9] Loss G: 0.6489, Loss D: 1.2733, D(x): 1.0336, D(G(z1)): 0.0167, D(G(z2)): -0.6489\n",
      "Epoch[0], Batch[10] Loss G: 0.8229, Loss D: 1.1005, D(x): 1.3987, D(G(z1)): -0.0301, D(G(z2)): -0.8229\n",
      "Epoch[0], Batch[11] Loss G: 1.1258, Loss D: 0.7506, D(x): 1.7397, D(G(z1)): -0.2890, D(G(z2)): -1.1258\n",
      "Epoch[0], Batch[12] Loss G: 1.5539, Loss D: 0.5454, D(x): 1.6250, D(G(z1)): -0.4954, D(G(z2)): -1.5539\n",
      "Epoch[0], Batch[13] Loss G: 1.1892, Loss D: 0.6345, D(x): 0.9185, D(G(z1)): -0.6062, D(G(z2)): -1.1892\n",
      "Epoch[0], Batch[14] Loss G: 0.7919, Loss D: 1.9605, D(x): 3.2847, D(G(z1)): 0.9437, D(G(z2)): -0.7919\n",
      "Epoch[0], Batch[15] Loss G: 0.7111, Loss D: 2.1962, D(x): 2.5307, D(G(z1)): 1.1962, D(G(z2)): -0.7111\n",
      "Epoch[0], Batch[16] Loss G: 0.3626, Loss D: 2.2263, D(x): 0.1359, D(G(z1)): 0.2976, D(G(z2)): -0.3626\n",
      "Epoch[0], Batch[17] Loss G: 0.6461, Loss D: 1.4075, D(x): 1.2902, D(G(z1)): 0.3057, D(G(z2)): -0.6461\n",
      "Epoch[0], Batch[18] Loss G: 1.2063, Loss D: 0.8304, D(x): 1.2791, D(G(z1)): -0.2454, D(G(z2)): -1.2063\n",
      "Epoch[0], Batch[19] Loss G: 1.6721, Loss D: 0.4349, D(x): 0.9044, D(G(z1)): -0.8430, D(G(z2)): -1.6721\n",
      "Epoch[0], Batch[20] Loss G: 1.7922, Loss D: 0.0574, D(x): 1.9105, D(G(z1)): -1.0214, D(G(z2)): -1.7922\n",
      "Epoch[0], Batch[21] Loss G: 2.1953, Loss D: 0.3806, D(x): 2.3243, D(G(z1)): -0.6783, D(G(z2)): -2.1953\n",
      "Epoch[0], Batch[22] Loss G: 2.0175, Loss D: 0.5086, D(x): 1.5678, D(G(z1)): -0.8101, D(G(z2)): -2.0175\n",
      "Epoch[0], Batch[23] Loss G: 1.7632, Loss D: 0.9202, D(x): 1.7078, D(G(z1)): -0.3060, D(G(z2)): -1.7632\n",
      "Epoch[0], Batch[24] Loss G: 1.8561, Loss D: 0.9213, D(x): 2.4381, D(G(z1)): -0.1388, D(G(z2)): -1.8561\n",
      "Epoch[0], Batch[25] Loss G: 2.0993, Loss D: 0.5232, D(x): 2.2031, D(G(z1)): -0.5894, D(G(z2)): -2.0993\n",
      "Epoch[0], Batch[26] Loss G: 2.4568, Loss D: 0.1366, D(x): 2.5744, D(G(z1)): -0.9132, D(G(z2)): -2.4568\n",
      "Epoch[0], Batch[27] Loss G: 2.9741, Loss D: 0.1587, D(x): 2.6139, D(G(z1)): -0.9189, D(G(z2)): -2.9741\n",
      "Epoch[0], Batch[28] Loss G: 1.5132, Loss D: 0.3567, D(x): 1.3714, D(G(z1)): -1.1625, D(G(z2)): -1.5132\n",
      "Epoch[0], Batch[29] Loss G: 0.4366, Loss D: 2.6962, D(x): 3.5906, D(G(z1)): 1.6794, D(G(z2)): -0.4366\n",
      "Epoch[0], Batch[30] Loss G: 1.4255, Loss D: 2.2227, D(x): 2.2387, D(G(z1)): 1.2036, D(G(z2)): -1.4255\n",
      "Epoch[1], Batch[0] Loss G: 2.8966, Loss D: 1.3831, D(x): 0.7438, D(G(z1)): -0.5254, D(G(z2)): -2.8966\n",
      "Epoch[1], Batch[1] Loss G: 1.2153, Loss D: 1.8148, D(x): -0.2338, D(G(z1)): -1.5865, D(G(z2)): -1.2153\n",
      "Epoch[1], Batch[2] Loss G: 0.3644, Loss D: 2.3345, D(x): 0.6251, D(G(z1)): 0.2966, D(G(z2)): -0.3644\n",
      "Epoch[1], Batch[3] Loss G: 0.2949, Loss D: 2.0846, D(x): 1.7365, D(G(z1)): 0.6402, D(G(z2)): -0.2949\n",
      "Epoch[1], Batch[4] Loss G: 0.6498, Loss D: 1.7288, D(x): 1.2741, D(G(z1)): 0.3143, D(G(z2)): -0.6498\n",
      "Epoch[1], Batch[5] Loss G: 0.8288, Loss D: 1.4083, D(x): 0.4667, D(G(z1)): -0.2028, D(G(z2)): -0.8288\n",
      "Epoch[1], Batch[6] Loss G: 1.0253, Loss D: 1.3045, D(x): 0.4162, D(G(z1)): -0.3296, D(G(z2)): -1.0253\n",
      "Epoch[1], Batch[7] Loss G: 1.2707, Loss D: 1.1776, D(x): 0.4488, D(G(z1)): -0.4524, D(G(z2)): -1.2707\n",
      "Epoch[1], Batch[8] Loss G: 1.7110, Loss D: 0.9404, D(x): 0.7459, D(G(z1)): -0.4702, D(G(z2)): -1.7110\n",
      "Epoch[1], Batch[9] Loss G: 1.2280, Loss D: 0.8374, D(x): 0.6627, D(G(z1)): -0.8618, D(G(z2)): -1.2280\n",
      "Epoch[1], Batch[10] Loss G: 1.1342, Loss D: 1.3366, D(x): 1.3687, D(G(z1)): 0.0906, D(G(z2)): -1.1342\n",
      "Epoch[1], Batch[11] Loss G: 0.8592, Loss D: 1.5566, D(x): 1.4095, D(G(z1)): 0.2227, D(G(z2)): -0.8592\n",
      "Epoch[1], Batch[12] Loss G: 0.0798, Loss D: 1.7666, D(x): 1.1193, D(G(z1)): 0.2426, D(G(z2)): -0.0798\n",
      "Epoch[1], Batch[13] Loss G: 0.5794, Loss D: 1.6222, D(x): 2.6089, D(G(z1)): 0.5741, D(G(z2)): -0.5794\n",
      "Epoch[1], Batch[14] Loss G: 1.1372, Loss D: 1.3635, D(x): 1.6218, D(G(z1)): -0.0856, D(G(z2)): -1.1372\n",
      "Epoch[1], Batch[15] Loss G: 0.9334, Loss D: 1.1683, D(x): 1.6344, D(G(z1)): -0.6524, D(G(z2)): -0.9334\n",
      "Epoch[1], Batch[16] Loss G: 0.8717, Loss D: 1.0417, D(x): 2.0548, D(G(z1)): -0.5497, D(G(z2)): -0.8717\n",
      "Epoch[1], Batch[17] Loss G: 0.5931, Loss D: 1.0265, D(x): 2.5850, D(G(z1)): -0.4036, D(G(z2)): -0.5931\n",
      "Epoch[1], Batch[18] Loss G: 0.6689, Loss D: 1.0215, D(x): 3.0442, D(G(z1)): -0.2532, D(G(z2)): -0.6689\n",
      "Epoch[1], Batch[19] Loss G: 0.4821, Loss D: 1.0726, D(x): 2.9335, D(G(z1)): -0.3344, D(G(z2)): -0.4821\n",
      "Epoch[1], Batch[20] Loss G: 0.3643, Loss D: 1.0774, D(x): 2.8211, D(G(z1)): -0.1361, D(G(z2)): -0.3643\n",
      "Epoch[1], Batch[21] Loss G: 0.3114, Loss D: 1.1749, D(x): 3.7132, D(G(z1)): 0.0102, D(G(z2)): -0.3114\n",
      "Epoch[1], Batch[22] Loss G: 0.1893, Loss D: 1.1418, D(x): 3.2800, D(G(z1)): -0.0119, D(G(z2)): -0.1893\n",
      "Epoch[1], Batch[23] Loss G: 0.3298, Loss D: 1.1713, D(x): 2.8366, D(G(z1)): 0.1198, D(G(z2)): -0.3298\n",
      "Epoch[1], Batch[24] Loss G: 0.2312, Loss D: 1.2647, D(x): 2.6615, D(G(z1)): 0.0126, D(G(z2)): -0.2312\n",
      "Epoch[1], Batch[25] Loss G: 0.0375, Loss D: 1.3322, D(x): 2.7157, D(G(z1)): 0.1673, D(G(z2)): -0.0375\n",
      "Epoch[1], Batch[26] Loss G: -0.2338, Loss D: 1.5886, D(x): 1.9649, D(G(z1)): 0.4066, D(G(z2)): 0.2338\n",
      "Epoch[1], Batch[27] Loss G: -0.3272, Loss D: 1.6623, D(x): 2.3529, D(G(z1)): 0.5899, D(G(z2)): 0.3272\n",
      "Epoch[1], Batch[28] Loss G: -0.3641, Loss D: 1.7495, D(x): 1.7997, D(G(z1)): 0.6091, D(G(z2)): 0.3641\n",
      "Epoch[1], Batch[29] Loss G: -0.3547, Loss D: 1.7324, D(x): 1.8202, D(G(z1)): 0.5837, D(G(z2)): 0.3547\n",
      "Epoch[1], Batch[30] Loss G: -0.3314, Loss D: 1.6932, D(x): 1.2554, D(G(z1)): 0.4527, D(G(z2)): 0.3314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x1079485b0>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/typeorigin/anaconda3/envs/XArtist/lib/python3.8/site-packages/ipykernel/ipkernel.py\", line 770, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 6\u001B[0m\n\u001B[1;32m      4\u001B[0m start_ts \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining started ....\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m----> 6\u001B[0m \u001B[43mgan_trainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining finished ... (\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m(time\u001B[38;5;241m.\u001B[39mtime()\u001B[38;5;250m \u001B[39m\u001B[38;5;241m-\u001B[39m\u001B[38;5;250m \u001B[39mstart_ts)\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m1000\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m s)\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/PythonProjects/XArtist/training/src/gan_trainer.py:292\u001B[0m, in \u001B[0;36mrun\u001B[0;34m()\u001B[0m\n\u001B[1;32m    287\u001B[0m \u001B[38;5;66;03m# ===Wandb init finished===\u001B[39;00m\n\u001B[1;32m    288\u001B[0m \n\u001B[1;32m    289\u001B[0m \n\u001B[1;32m    290\u001B[0m \u001B[38;5;66;03m# summarize_performance(10, g_model, d_model, None, device, BATCH_SIZE, LATENT_DIM)\u001B[39;00m\n\u001B[1;32m    291\u001B[0m epoch \u001B[38;5;241m=\u001B[39m train_configs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEPOCHS\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m--> 292\u001B[0m \u001B[43mtrain_gan\u001B[49m\u001B[43m(\u001B[49m\u001B[43mg_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43md_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[43mdataloader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mepoch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_configs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mBATCH_SIZE\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlatent_dim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_configs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mLATENT_DIM\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mloss_type\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_configs\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mLOSS_FN\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    293\u001B[0m save_model(epoch, g_model, d_model)\n",
      "File \u001B[0;32m~/PythonProjects/XArtist/training/src/gan_trainer.py:127\u001B[0m, in \u001B[0;36mtrain_gan\u001B[0;34m(g_model, d_model, train_loader, device, epochs, batch_size, latent_dim, loss_type)\u001B[0m\n\u001B[1;32m    124\u001B[0m model_dumping_freq \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(train_configs[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mMODEL_DUMPING_FREQUENCY\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m    126\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m--> 127\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m b, batch_dataset \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[1;32m    128\u001B[0m         X_true, _ \u001B[38;5;241m=\u001B[39m batch_dataset\n\u001B[1;32m    129\u001B[0m         X_true \u001B[38;5;241m=\u001B[39m X_true\u001B[38;5;241m.\u001B[39mto(device)\n",
      "File \u001B[0;32m~/anaconda3/envs/XArtist/lib/python3.8/site-packages/torch/utils/data/dataloader.py:629\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    626\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    627\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    628\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 629\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    630\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    632\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    633\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/anaconda3/envs/XArtist/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1315\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1312\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1313\u001B[0m     \u001B[38;5;66;03m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001B[39;00m\n\u001B[1;32m   1314\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_persistent_workers:\n\u001B[0;32m-> 1315\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_shutdown_workers\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1316\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m\n\u001B[1;32m   1318\u001B[0m \u001B[38;5;66;03m# Now `self._rcvd_idx` is the batch index we want to fetch\u001B[39;00m\n\u001B[1;32m   1319\u001B[0m \n\u001B[1;32m   1320\u001B[0m \u001B[38;5;66;03m# Check if the next sample has already been generated\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/XArtist/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1440\u001B[0m, in \u001B[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1435\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_mark_worker_as_unavailable(worker_id, shutdown\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m   1436\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m w \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_workers:\n\u001B[1;32m   1437\u001B[0m     \u001B[38;5;66;03m# We should be able to join here, but in case anything went\u001B[39;00m\n\u001B[1;32m   1438\u001B[0m     \u001B[38;5;66;03m# wrong, we set a timeout and if the workers fail to join,\u001B[39;00m\n\u001B[1;32m   1439\u001B[0m     \u001B[38;5;66;03m# they are killed in the `finally` block.\u001B[39;00m\n\u001B[0;32m-> 1440\u001B[0m     \u001B[43mw\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m_utils\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mMP_STATUS_CHECK_INTERVAL\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1441\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m q \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_index_queues:\n\u001B[1;32m   1442\u001B[0m     q\u001B[38;5;241m.\u001B[39mcancel_join_thread()\n",
      "File \u001B[0;32m~/anaconda3/envs/XArtist/lib/python3.8/multiprocessing/process.py:149\u001B[0m, in \u001B[0;36mBaseProcess.join\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parent_pid \u001B[38;5;241m==\u001B[39m os\u001B[38;5;241m.\u001B[39mgetpid(), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcan only join a child process\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_popen \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcan only join a started process\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 149\u001B[0m res \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_popen\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    150\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m res \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    151\u001B[0m     _children\u001B[38;5;241m.\u001B[39mdiscard(\u001B[38;5;28mself\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/XArtist/lib/python3.8/multiprocessing/popen_fork.py:44\u001B[0m, in \u001B[0;36mPopen.wait\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m timeout \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m     43\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmultiprocessing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconnection\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m wait\n\u001B[0;32m---> 44\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[43mwait\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msentinel\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[1;32m     45\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     46\u001B[0m \u001B[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/XArtist/lib/python3.8/multiprocessing/connection.py:931\u001B[0m, in \u001B[0;36mwait\u001B[0;34m(object_list, timeout)\u001B[0m\n\u001B[1;32m    928\u001B[0m     deadline \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mmonotonic() \u001B[38;5;241m+\u001B[39m timeout\n\u001B[1;32m    930\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 931\u001B[0m     ready \u001B[38;5;241m=\u001B[39m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mselect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    932\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ready:\n\u001B[1;32m    933\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m [key\u001B[38;5;241m.\u001B[39mfileobj \u001B[38;5;28;01mfor\u001B[39;00m (key, events) \u001B[38;5;129;01min\u001B[39;00m ready]\n",
      "File \u001B[0;32m~/anaconda3/envs/XArtist/lib/python3.8/selectors.py:415\u001B[0m, in \u001B[0;36m_PollLikeSelector.select\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    413\u001B[0m ready \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    414\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 415\u001B[0m     fd_event_list \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_selector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpoll\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtimeout\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    416\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mInterruptedError\u001B[39;00m:\n\u001B[1;32m    417\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m ready\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
